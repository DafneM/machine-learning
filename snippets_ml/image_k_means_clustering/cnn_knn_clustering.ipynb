{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.decomposition import PCA\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"dataset\"\n",
    "IMAGE_SIZE = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224,224,3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list comprehension of this was extremely long, not comprehensive\n",
    "def list_image_paths(dataset_path):\n",
    "    image_path_list = []\n",
    "    for folder_path in os.listdir(dataset_path):\n",
    "        for image_path in os.listdir(os.path.join(dataset_path, folder_path)):\n",
    "            image_path_list.append(os.path.join(dataset_path, folder_path, image_path))\n",
    "    return image_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vector(path, img_size, image_path_list):\n",
    "    feature_vector = []\n",
    "    for img_path in image_path_list:\n",
    "        img = image.load_img(img_path, target_size=img_size)\n",
    "        img = image.img_to_array(img)\n",
    "        img = preprocess_input(img)\n",
    "        x = np.expand_dims(img, 0)\n",
    "        feature = model.predict(x)    \n",
    "        feature_np = np.array(feature)\n",
    "        feature_vector.append(feature_np.flatten())\n",
    "    return np.array(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_list = list_image_paths(DATASET_PATH)\n",
    "feature_vector = extract_vector(DATASET_PATH, IMAGE_SIZE, image_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters=3, \n",
    "max_iter=5, \n",
    "n_init=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp, classified_points, means = cv2.kmeans(\n",
    "#     data=feature_vector, \n",
    "#     K=n_clusters, \n",
    "#     bestLabels=None, \n",
    "#     criteria=(cv2.TERM_CRITERIA_MAX_ITER, max_iter, 0.9), \n",
    "#     attempts=n_init,\n",
    "#     flags=cv2.KMEANS_PP_CENTERS\n",
    "# )\n",
    "temp, classified_points, means = cv2.kmeans(\n",
    "    feature_vector,\n",
    "    3, \n",
    "    bestLabels=None, \n",
    "    criteria=(cv2.TERM_CRITERIA_MAX_ITER, 1500000, 0.9), \n",
    "    attempts=2000000, \n",
    "    flags=cv2.KMEANS_PP_CENTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(image_path_list, [p[0] for p in classified_points]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(\n",
    "    n_clusters=n_clusters, \n",
    "    max_iter=max_iter, \n",
    "    n_init=n_init, \n",
    "    random_state=random_state).fit(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [image_path_list[i] for i in range(len(kmeans.labels_))]\n",
    "dict(zip(paths, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = PCA(n_components=2).fit_transform(feature_vector)\n",
    "kmeans = KMeans(\n",
    "    init='k-means++', \n",
    "    n_clusters=n_clusters, \n",
    "    max_iter=max_iter, \n",
    "    n_init=n_init, \n",
    "    random_state=random_state).fit(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [image_path_list[i] for i in range(len(kmeans.labels_))]\n",
    "dict(zip(paths, kmeans.labels_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
